{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f98bbad",
   "metadata": {},
   "source": [
    "# Audio Capture & Augmentation\n",
    "#### Author: Jeromey Schwartz\n",
    "#### *Audio capture code (indicated with *) supplied by Dr. Jeremy Holleman UNC-Charlotte "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e85322b",
   "metadata": {},
   "source": [
    "### Purpose:\n",
    "This will record an audio sample 1 second long at a sampling rate of 16kHz, the samples can then be augmented by adding noise, pitch shifting, or time shifting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0398a4",
   "metadata": {},
   "source": [
    "### Program Flow:\n",
    "1. Load libraries/setup code \n",
    "2. Save a number of audio samples \n",
    "3. Save ambient noise samples \n",
    "4. Noise shift \n",
    "5. Time shift \n",
    "6. Pitch shift \n",
    "7. Save samples names in validation document "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd7b44af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4914f189",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0c1da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 20:23:37.167796: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-04 20:23:37.197315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 20:23:37.635272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PY_SSIZE_T_CLEAN'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "from datetime import datetime as dt\n",
    "from numpy import log as ln\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import pyaudio\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import math\n",
    "import time\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93e449",
   "metadata": {},
   "source": [
    "#### Set Parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e632d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i16min            = -32768\n",
    "i16max            = 32767\n",
    "fsamp             = 16000\n",
    "wave_length_ms    = 1000\n",
    "wave_length_samps = 16000\n",
    "window_size_ms    = 60\n",
    "window_step_ms    = 40\n",
    "num_filters       = 32\n",
    "use_microfrontend = True\n",
    "keyword        = 'computer'#####Insert your keyword\n",
    "spectrogram_shape = (64, 24, 32, 1)\n",
    "\n",
    "chunk_duration = 0.25 # Each read length in seconds from mic.\n",
    "fs = 16000 # sampling rate for mic\n",
    "sample_rate = 16000 # sampling rate for mic\n",
    "chunk_samples = int(fs * chunk_duration) # Each read length in number of samples.\n",
    "\n",
    "# Each model input data duration in seconds, need to be an integer numbers of chunk_duration\n",
    "feed_duration = 1.0\n",
    "feed_samples = int(fs * feed_duration)\n",
    "\n",
    "assert feed_duration/chunk_duration == int(feed_duration/chunk_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6456e",
   "metadata": {},
   "source": [
    "#### Create keyword & noise folders*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b7bdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/GitHub/project-2-team-1/training/custom-speech/computer/\n",
      "Directory 'computer' created\n",
      "Directory 'noise' created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the parent directory\n",
    "parent_dir = os.getcwd()\n",
    "parent_dir = os.path.join(parent_dir, \"custom-speech\")\n",
    "\n",
    "# Get the name of the current keyword\n",
    "keyword = \"computer\"\n",
    "\n",
    "# Create the folder name and path\n",
    "folder = keyword\n",
    "dir = os.path.join(parent_dir, folder)\n",
    "\n",
    "# Create the directories if they do not exist\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "folder = keyword\n",
    "dir = os.path.join(parent_dir, folder)\n",
    "noise_dir = os.path.join(parent_dir, \"noise\")\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "if not os.path.exists(noise_dir):\n",
    "    os.mkdir(noise_dir)\n",
    "\n",
    "keyword_directory = dir + '/'\n",
    "print(keyword_directory)\n",
    "\n",
    "# Check if the directories were created\n",
    "if os.path.exists(os.path.join(parent_dir, \"computer\")):\n",
    "    print(\"Directory 'computer' created\")\n",
    "if os.path.exists(os.path.join(parent_dir, \"noise\")):\n",
    "    print(\"Directory 'noise' created\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2691401",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d33f91",
   "metadata": {},
   "source": [
    "# Get Custom Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc895e",
   "metadata": {},
   "source": [
    "#### Run this code to get in an audio sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace0223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default input device:\n",
      "{'index': 0, 'structVersion': 2, 'name': 'HDA Intel PCH: ALC897 Analog (hw:0,0)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.005804988662131519, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': 0.034829931972789115, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "\n",
      "Default output device:\n",
      "{'index': 0, 'structVersion': 2, 'name': 'HDA Intel PCH: ALC897 Analog (hw:0,0)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.005804988662131519, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': 0.034829931972789115, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "# Create a PyAudio object\n",
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "# Get the default input and output devices\n",
    "default_input_device = pa.get_default_input_device_info()\n",
    "default_output_device = pa.get_default_output_device_info()\n",
    "\n",
    "# Print information about the default devices\n",
    "print(\"Default input device:\")\n",
    "print(default_input_device)\n",
    "\n",
    "print(\"\\nDefault output device:\")\n",
    "print(default_output_device)\n",
    "\n",
    "# # Print information about all available devices\n",
    "# print(\"\\nAvailable devices:\")\n",
    "# for i in range(pa.get_device_count()):\n",
    "#     device_info = pa.get_device_info_by_index(i)\n",
    "#     print(device_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00064e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=10, micro=10, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info.\")\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288e6ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Queue to communiate between the audio callback and main thread\n",
    "q = Queue()\n",
    "run = True\n",
    "silence_threshold = 100\n",
    "# Run the demo for a timeout seconds\n",
    "timeout = time.time() + 1 \n",
    "# Data buffer for the input wavform\n",
    "data = np.zeros(feed_samples, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > feed_samples:\n",
    "        data = data[-feed_samples:]\n",
    "        # Process data async by sending a queue.\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = pyaudio.PyAudio().open(\n",
    "    format=pyaudio.paInt16,\n",
    "    channels=1,\n",
    "    rate=fs,\n",
    "    input=True,\n",
    "    frames_per_buffer=chunk_samples,\n",
    "    input_device_index=23,\n",
    "    stream_callback=callback)\n",
    "stream.start_stream()\n",
    "try:\n",
    "    while run:        \n",
    "        data = q.get()\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False      \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "sample_rate = fs\n",
    "\n",
    "\n",
    "#Displaying wave file data\n",
    "plt.plot(np.arange(1*fs)/fs, data)\n",
    "plt.show()\n",
    "ipd.Audio(data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ac719",
   "metadata": {},
   "source": [
    "#### If the Sample looks good run cell below to save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802139e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #saving the wave file to training_data\n",
    "# date_str = dt.now().strftime(\"%H%M%S\").lower()\n",
    "# current_name = f\"{keyword_directory}{keyword}_{date_str}.wav\".replace(\"\\\\\", \"/\")\n",
    "# write(current_name, sample_rate, data)\n",
    "# print(\"Audio sample saved\")\n",
    "# print(current_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32de0a5",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "* To get noise data run \"get data\" loop again to get ambient room\n",
    "* Save here\n",
    "* Get ~3 samples total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the wave file to training_data\n",
    "date_str = dt.now().strftime(\"%H%M%S\").lower()\n",
    "current_name = f\"{parent_dir}/noise/noise_{date_str}.wav\"\n",
    "write(current_name, sample_rate, data)\n",
    "print(\"Audio sample saved as noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c59cc",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Noise\n",
    "    * This will create copies of sample audio and add pre-recorded noise. \n",
    "    * The amplitude of the noise depends on *noise_count*\n",
    "    * Audio samples and visualizations are created to show noise augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7813e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting augmentation folder & files\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "\n",
    "#Testing if audio data imported correctly\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading noise samples\n",
    "noise_dir = parent_dir+'/noise'\n",
    "noise_samples = tf.io.gfile.glob(str(noise_dir) + '/*.wav')\n",
    "print(\"Noise Samples:\", len(noise_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca02bd",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b00e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise_count will deteremine how many augmentations will be created\n",
    "    #noise_count=1 will be a copy with noise augmentation * 0\n",
    "    #noise_count=2 will be noise_count=1 plus a copy with noise augmentation * 1\n",
    "    #noise_count=2 will be noise_count=2 plus a copy with noise augmentation * 2  \n",
    "    #and so on \n",
    "\n",
    "noise_count=4\n",
    "print(\"This will expand the current\", len(filenames), \"files by creating an addtional\",len(filenames)*len(noise_samples)*noise_count, \"noise augmented files, to give a total of\",len(filenames)*len(noise_samples)*(noise_count)+len(filenames),\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a67c2c",
   "metadata": {},
   "source": [
    "#### Creating Noise Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict holds samples for plotting\n",
    "noise_dict={}\n",
    "for index in range(len(filenames)):\n",
    "    test_wav=filenames[index]\n",
    "    fs, test_wav = wavfile.read(test_wav)\n",
    "    if (len(test_wav) < fs):\n",
    "        padding=fs-len(test_wav)\n",
    "        extra_padding=np.zeros(padding).astype(np.int16) #array of empty audio to pad with\n",
    "        test_wav=np.concatenate((test_wav,extra_padding),axis=0).astype(np.int16)\n",
    "    noise_dict[0]=test_wav.astype(np.int16)\n",
    "    for i in range(len(noise_samples)):\n",
    "        noise=noise_samples[i]\n",
    "        fs, noise = wavfile.read(noise)\n",
    "        for j in range(noise_count):\n",
    "            noise_multiplier=round(max(test_wav)*(j/2000))\n",
    "            noise_lvl=noise*noise_multiplier\n",
    "            test_wave_with_noise=np.add(test_wav,noise_lvl)\n",
    "            current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_Noise{i}_Multiplier{j}.wav\"\n",
    "            write(current_name, fs, test_wave_with_noise)\n",
    "            noise_dict[j+1]=test_wave_with_noise.astype(np.int16)\n",
    "            noise_dict[j+5]=noise_lvl.astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b9b33",
   "metadata": {},
   "source": [
    "#### Plotting noise augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only plots up to noise lvl 3\n",
    "fig, axs = plt.subplots(4, 4,figsize=(20,10), sharex=True,sharey=True)\n",
    "axs[0,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[0,1].plot(np.arange(1*fs)/fs, noise_dict[5], 'tab:orange')\n",
    "axs[0,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[0,2].plot(np.arange(1*fs)/fs, noise_dict[5])\n",
    "axs[0,3].plot(np.arange(1*fs)/fs, noise_dict[1])\n",
    "\n",
    "axs[0, 0].set_title(\"Original\")\n",
    "axs[0, 1].set_title(\"Noise\")\n",
    "axs[0, 2].set_title(\"Original + Noise\")\n",
    "axs[0, 3].set_title(\"Augmented Audio\")\n",
    "\n",
    "axs[0, 0].set(xlabel='Time (s)', ylabel='Noise lvl 0')\n",
    "axs[1, 0].set(xlabel='Time (s)', ylabel='Noise lvl 1')\n",
    "axs[2, 0].set(xlabel='Time (s)', ylabel='Noise lvl 2')\n",
    "axs[3, 0].set(xlabel='Time (s)', ylabel='Noise lvl 3')\n",
    "\n",
    "axs[1,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[1,1].plot(np.arange(1*fs)/fs, noise_dict[6], 'tab:orange')\n",
    "axs[1,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[1,2].plot(np.arange(1*fs)/fs, noise_dict[6])\n",
    "axs[1,3].plot(np.arange(1*fs)/fs, noise_dict[2])\n",
    "\n",
    "axs[2,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[2,1].plot(np.arange(1*fs)/fs, noise_dict[7], 'tab:orange')\n",
    "axs[2,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[2,2].plot(np.arange(1*fs)/fs, noise_dict[7])\n",
    "axs[2,3].plot(np.arange(1*fs)/fs, noise_dict[3])\n",
    "\n",
    "axs[3,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[3,1].plot(np.arange(1*fs)/fs, noise_dict[8], 'tab:orange')\n",
    "axs[3,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[3,2].plot(np.arange(1*fs)/fs, noise_dict[8])\n",
    "axs[3,3].plot(np.arange(1*fs)/fs, noise_dict[4])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Time (s)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f4855",
   "metadata": {},
   "source": [
    "#### Listen to noise augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c692f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only samples up to noise lvl 3\n",
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Noise lvl 0:\")\n",
    "display(Audio(noise_dict[0], rate=fs))\n",
    "print(\"Noise lvl 1:\")\n",
    "display(Audio(noise_dict[2], rate=fs))\n",
    "print(\"Noise lvl 2:\")\n",
    "display(Audio(noise_dict[3], rate=fs))\n",
    "print(\"Noise lvl 3:\")\n",
    "display(Audio(noise_dict[4], rate=fs))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87ac19ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "84c5fac5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2290394e",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Time Shift\n",
    "    * This will create copies of sample audio and shift them forward or backward in time in 1/8s increments \n",
    "    * The \"empty space\" created by the time shift is filled with artificial noise (created in cell 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Testing if audio data imported correctly\n",
    "filenames[0]\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing variables for 1/8th second time shifts\n",
    "one_eighth=int((sample_rate/8)) #16k sample rate means 2k for 1/8s\n",
    "padding=one_eighth #Number of samples to pad\n",
    "#zero_padding=np.zeros(padding).astype(np.int16) #array of empty audio to pad with\n",
    "noise_lvl_min=-200 #about the min for quiet room when measured with get audio code above\n",
    "noise_lvl_max=200 #about the max for quiet room when measured with get audio code above\n",
    "noise_padding=np.random.randint(noise_lvl_min,noise_lvl_max+1,padding) #makes random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b271b2a",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many of each type of time shift is desired..in 1/8s increments\n",
    "#suggest following bell curve with center being zero_shift and left_3/right_3 being the extremes\n",
    "\n",
    "left_3=1\n",
    "left_2=2\n",
    "left_1=2\n",
    "zero_shift=2\n",
    "right_1=2\n",
    "right_2=2\n",
    "right_3=1\n",
    "\n",
    "total=zero_shift+right_3+right_2+right_1+left_3+left_2+left_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf71ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"This will expand the current\", len(filenames), \"files by creating an addtional\",len(filenames)*total, \"time shifted files, to give a total of\",len(filenames)*(total+1),\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc3cbe",
   "metadata": {},
   "source": [
    "#### Time Shift Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a648746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold audio for data visualization\n",
    "audio_dict = {}\n",
    "\n",
    "##This will randomize audio samples\n",
    "#random_list = list(range(0, len(filenames))) #create array [1,2,3...]\n",
    "#random.shuffle(random_list) #randomize the array\n",
    "\n",
    "#This will reverse the list so the element printed in next cell shows augmentation to original sample\n",
    "random_list = list(range(0, len(filenames))) #create array [1,2,3...]\n",
    "random_list.reverse() #randomize the array\n",
    "\n",
    "#creates dictionary to hold audio for data visualization\n",
    "audio_dict={}\n",
    "\n",
    "##This will randomize audio samples\n",
    "#random_list = list(range(0, len(filenames))) #create array [1,2,3...]\n",
    "#random.shuffle(random_list) #randomize the array\n",
    "\n",
    "#This will reverse the list so the element printed in next cell shows augmentation to original sample\n",
    "random_list = list(range(0, len(filenames))) #create array [1,2,3...]\n",
    "random_list.reverse() #randomize the array\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#runs 5x shifts audio from original to left by .5sec in 1/8s increments\n",
    "for index in tqdm(range(len(filenames)), desc=\"Augmenting audio\"):\n",
    "    test_wav=filenames[random_list[index]]\n",
    "    fs, test_wav = wavfile.read(test_wav)\n",
    "    audio_dict[0]=test_wav.astype(np.int16)#dict[0] holds original audio\n",
    "    test_wav_decrease = test_wav #creating copy to be manipulated \n",
    "    test_wav_increase = test_wav #creating copy to be manipulated\n",
    "    \n",
    "    #shift audio to left in 1/8s increments\n",
    "    for j in range(1,4):#dict 1-4 hold shifted audio (change 4 to 5 to make 1/2s shift)\n",
    "        for i in range (one_eighth):\n",
    "            test_wav_decrease=np.delete(test_wav_decrease,0)\n",
    "        test_wav_decrease=np.concatenate((test_wav_decrease,noise_padding),axis=0).astype(np.int16)\n",
    "        audio_dict[j]=test_wav_decrease.astype(np.int16)\n",
    "        if (j==1):\n",
    "            for p in range(left_1): #creates left_1 copys shifted left 1/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_LShift{j}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (j==2):\n",
    "            for p in range(left_2): #creates left_2 copys shifted left 2/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_LShift{j}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (j==3):\n",
    "            for p in range(left_3): #creates left_3 copy shifted left 3/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_LShift{j}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "\n",
    "    \n",
    "    #shift audio to right in 1/8s increments\n",
    "    for k in range(6,9):\n",
    "        #pad zeros to front\n",
    "        test_wav_increase=np.concatenate((noise_padding,test_wav_increase),axis=0)\n",
    "        #delete data past 16k samples\n",
    "        for d in range(sample_rate,len(test_wav_increase)):\n",
    "            test_wav_increase=np.delete(test_wav_increase,sample_rate,0).astype(np.int16)\n",
    "        audio_dict[k]=test_wav_increase\n",
    "        if (k==6):\n",
    "            for p in range(right_1): #creates right_1 copys shifted right 1/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_RShift{k-5}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (k==7):\n",
    "            for p in range(right_2): #creates right_2 copys shifted right 2/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_RShift{k-5}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (k==8):\n",
    "            for p in range(right_3): #creates right_3 copy shifted right 3/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_RShift{k-5}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "    for l in range(zero_shift):\n",
    "        current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_NoShift_{l}.wav\"\n",
    "        write(current_name, fs, test_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47f189",
   "metadata": {},
   "source": [
    "#### Plot time shifted audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175891fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out is for half second shift if desired\n",
    "\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "axs = fig.add_gridspec(3, 3)\n",
    "\n",
    "f_ax0 = fig.add_subplot(axs[0, 1])\n",
    "f_ax1 = fig.add_subplot(axs[1, 0])\n",
    "f_ax2 = fig.add_subplot(axs[1, 1])\n",
    "f_ax3 = fig.add_subplot(axs[1, 2])\n",
    "# f_ax4 = fig.add_subplot(axs[2, 3])\n",
    "f_ax6 = fig.add_subplot(axs[2, 0])\n",
    "f_ax7 = fig.add_subplot(axs[2, 1])\n",
    "f_ax8 = fig.add_subplot(axs[2, 2])\n",
    "# f_ax9 = fig.add_subplot(axs[3, 3])\n",
    "\n",
    "f_ax0.plot(np.arange(1*fs)/fs, audio_dict[0])\n",
    "f_ax1.plot(np.arange(1*fs)/fs, audio_dict[1])\n",
    "f_ax2.plot(np.arange(1*fs)/fs, audio_dict[2])\n",
    "f_ax3.plot(np.arange(1*fs)/fs, audio_dict[3])\n",
    "# f_ax4.plot(np.arange(1*fs)/fs, audio_dict[4])\n",
    "f_ax6.plot(np.arange(1*fs)/fs, audio_dict[6])\n",
    "f_ax7.plot(np.arange(1*fs)/fs, audio_dict[7])\n",
    "f_ax8.plot(np.arange(1*fs)/fs, audio_dict[8])\n",
    "# f_ax9.plot(np.arange(1*fs)/fs, audio_dict[9])\n",
    "\n",
    "f_ax0.set_title('Original')\n",
    "f_ax1.set_title('Shifted left 1/8')\n",
    "f_ax2.set_title('Shifted left 1/4')\n",
    "f_ax3.set_title('Shifted left 3/8')\n",
    "# f_ax4.set_title('Shifted left 1/2')\n",
    "f_ax6.set_title('Shifted right 1/8')\n",
    "f_ax7.set_title('Shifted right 1/4')\n",
    "f_ax8.set_title('Shifted right 3/8')\n",
    "# f_ax9.set_title('Shifted right 1/2')\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ec8e7",
   "metadata": {},
   "source": [
    "#### Listen to time shifted Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f81651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Original:\")\n",
    "display(Audio(audio_dict[0], rate=fs))\n",
    "print(\"Shifted left 1/8:\")\n",
    "display(Audio(audio_dict[1], rate=fs))\n",
    "print(\"Shifted left 1/4:\")\n",
    "display(Audio(audio_dict[2], rate=fs))\n",
    "print(\"Shifted left 3/8:\")\n",
    "display(Audio(audio_dict[3], rate=fs))\n",
    "# print(\"Shifted left 1/2:\")\n",
    "# display(Audio(audio_dict[4], rate=fs))\n",
    "print(\"Shifted right 1/8:\")\n",
    "display(Audio(audio_dict[6], rate=fs))\n",
    "print(\"Shifted right 1/4:\")\n",
    "display(Audio(audio_dict[7], rate=fs))\n",
    "print(\"Shifted right 3/8:\")\n",
    "display(Audio(audio_dict[8], rate=fs))\n",
    "# print(\"Shifted right 1/2:\")\n",
    "# display(Audio(audio_dict[9], rate=fs))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f79480e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ffbb93cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b2f40a1",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Pitch Shift\n",
    "    * This will create copies of sample audio and pitch shift them\n",
    "    * The variable *pitch_shift* allows control over pitch\n",
    "    * The variable *desired_number_of_files* allows control of exactly how many samples to create\n",
    "    * The loop will continue creating copies until desired count is reached, including pitch shifting already pitch shifted copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Testing if audio data imported correctly\n",
    "filenames[0]\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The current number of files in directory is\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee19898",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77698bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOPED AUGMENTING HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490e2a9",
   "metadata": {},
   "source": [
    "# Write augmented data files to testing and validation .txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample count:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Verifying opens files correctly\n",
    "print(filenames[0])\n",
    "\n",
    "num_files=len(filenames)\n",
    "num_files\n",
    "print(\"Total files:\", num_files)\n",
    "\n",
    "#randomizes order of samples for validation list\n",
    "random_list = list(range(0, num_files)) #create array [1,2,3...]\n",
    "random.shuffle(random_list) #randomize the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f497c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Set the paths and file names for the train, test, and validation files\n",
    "train_file_name = './custom-speech/training_list.txt'\n",
    "test_file_name = './custom-speech/testing_list.txt'\n",
    "val_file_name = './custom-speech/validation_list.txt'\n",
    "\n",
    "# Set the split percentages\n",
    "train_pct = 0.7\n",
    "test_pct = 0.2\n",
    "val_pct = 0.1\n",
    "\n",
    "# Set the directory path containing the WAV files\n",
    "data_dir = './custom-speech'\n",
    "\n",
    "# Create a list of keywords (folder names)\n",
    "keywords = ['yes','right','left','computer']\n",
    "\n",
    "# Create an empty list to store all the WAV files\n",
    "wav_files = []\n",
    "\n",
    "# Iterate over all the keywords and add their respective WAV files to the list\n",
    "for keyword in keywords:\n",
    "    # Get a list of all WAV files in the keyword directory\n",
    "    keyword_files = tf.io.gfile.glob(str(os.path.join(data_dir, keyword)) + '/*.wav')\n",
    "    # Add the keyword files to the list of all WAV files\n",
    "    wav_files += keyword_files\n",
    "\n",
    "# Shuffle the files randomly\n",
    "random.shuffle(wav_files)\n",
    "\n",
    "# Calculate the number of files for each split\n",
    "num_files = len(wav_files)\n",
    "num_train = int(train_pct*num_files)\n",
    "num_test = int(test_pct*num_files)\n",
    "num_val = num_files - num_train - num_test\n",
    "\n",
    "# Append the train list file\n",
    "with open(train_file_name, 'a') as f:\n",
    "    for file in wav_files[:num_train]:\n",
    "        f.write(os.path.join(os.path.basename(os.path.dirname(file)), os.path.basename(file)) + '\\n')\n",
    "print(num_train, \"samples added to\", train_file_name)\n",
    "\n",
    "# Append the test list file\n",
    "with open(test_file_name, 'a') as f:\n",
    "    for file in wav_files[num_train:num_train+num_test]:\n",
    "        f.write(os.path.join(os.path.basename(os.path.dirname(file)), os.path.basename(file)) + '\\n')\n",
    "print(num_test, \"samples added to\", test_file_name)\n",
    "\n",
    "# Append the validation list file\n",
    "with open(val_file_name, 'a') as f:\n",
    "    for file in wav_files[num_train+num_test:]:\n",
    "        f.write(os.path.join(os.path.basename(os.path.dirname(file)), os.path.basename(file)) + '\\n')\n",
    "print(num_val, \"samples added to\", val_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = './custom-speech/'\n",
    "\n",
    "folder_counts = {}\n",
    "for subdir in os.listdir(data_dir):\n",
    "    subdir_path = os.path.join(data_dir, subdir)\n",
    "    if os.path.isdir(subdir_path) and subdir != 'speech_commands_v0.02':\n",
    "        folder_counts[subdir] = len([f for f in os.listdir(subdir_path) if f.endswith('.wav')])\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "sorted_keys = sorted(folder_counts.keys())\n",
    "plt.bar(range(len(folder_counts)), [folder_counts[key] for key in sorted_keys], align='center')\n",
    "plt.xticks(range(len(folder_counts)), sorted_keys, rotation=90)\n",
    "plt.ylabel('Number of WAV Files')\n",
    "plt.title('WAV Files by Folder')\n",
    "plt.savefig('/home/david/Documents/GitHub/project-2-team-1/training/figs/all wav files')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59406c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many of the files do you want to have total?\n",
    "desired_number_of_files=4000\n",
    "\n",
    "#How do you want to pitch shift\n",
    "    #positive=high pitch, negative = low pitch\n",
    "    #0.25 is a good value\n",
    "pitch_shift=0.25"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a226b7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa7c992",
   "metadata": {},
   "source": [
    "### Doubling Equation:   \n",
    "> $output=input * 2^{x}$\n",
    "\n",
    "*Here $x$ is the number of times input is doubled\n",
    "\n",
    "#### To get desired number of output files from input when loop doubles input every iteration of the for loop we solve for $x$:\n",
    "   \n",
    "> $x=\\log _{2}(\\frac{out}{in})$\\\n",
    "  $x=\\frac{\\ln (\\frac{out}{in})} {\\ln (2)}$\n",
    "                 \n",
    "#### Next $math.ceil()$ is used to round up to integer for loop iteration\n",
    "\n",
    "> $x=$ math.ceil$(\\frac{\\ln (out)}{\\ln (in)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doubling formula used to find range for outer for loop indexing with \"i\"\n",
    "outer_range= math.ceil((np.log(desired_number_of_files / len(filenames)) / np.log(2) ))\n",
    "outer_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d116a7",
   "metadata": {},
   "source": [
    "#### Pitch Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909afc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace line 11 with comment below if you want to create a custom # < len(filenames)...\n",
    "#                                                    ...comment out if statements and speed will improve significantly\n",
    "#for index in range(40000): \n",
    "\n",
    "pitch_dict={}\n",
    "for i in range(outer_range):\n",
    "    for index in range(len(filenames)):\n",
    "        test_wav=filenames[index]\n",
    "        fs, test_wav = wavfile.read(test_wav)\n",
    "        if i==0:\n",
    "            pitch_dict[i]=test_wav\n",
    "        test_wav_float=test_wav.astype(float)\n",
    "        test_wav_pitch_shifted = librosa.effects.pitch_shift(test_wav_float, sr=sample_rate, n_steps=pitch_shift*(i+1))\n",
    "        test_wav_pitch_shifted_int=test_wav_pitch_shifted.astype(np.int16)\n",
    "        current_name = str(keyword_directory)+str(keyword) +f\"_Pitch_Shift_{i}_{index}.wav\"    \n",
    "        write(current_name, fsamp, test_wav_pitch_shifted_int)\n",
    "\n",
    "        files_in_folder=len(tf.io.gfile.glob(str(data_dir) + '/*.wav'))\n",
    "        pitch_dict[i+1]=test_wav_pitch_shifted_int\n",
    "        if (files_in_folder >= desired_number_of_files):\n",
    "            break \n",
    "    filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "    #update filenames with newly created files    \n",
    "    if (files_in_folder >= desired_number_of_files):\n",
    "        break \n",
    "print(\"Congratulations, the current number of files in directory is\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4aea1e",
   "metadata": {},
   "source": [
    "#### Plot Pitch Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True)\n",
    "axs = fig.add_gridspec(3, 3)\n",
    "\n",
    "f_ax0 = fig.add_subplot(axs[0, 1])\n",
    "f_ax1 = fig.add_subplot(axs[1, 0])\n",
    "f_ax2 = fig.add_subplot(axs[1, 1])\n",
    "f_ax3 = fig.add_subplot(axs[1, 2])\n",
    "f_ax4 = fig.add_subplot(axs[2, 0])\n",
    "f_ax5 = fig.add_subplot(axs[2, 1])\n",
    "f_ax6 = fig.add_subplot(axs[2, 2])\n",
    "\n",
    "f_ax0.plot(np.arange(1*fs)/fs, pitch_dict[0])\n",
    "f_ax0.set_title('Original')\n",
    "\n",
    "if outer_range>1:\n",
    "    f_ax1.plot(np.arange(1*fs)/fs, pitch_dict[1])\n",
    "    f_ax1.set_title('Pitch Shift lvl 1')\n",
    "if outer_range>2:\n",
    "    f_ax2.plot(np.arange(1*fs)/fs, pitch_dict[2])\n",
    "    f_ax2.set_title('Pitch Shift lvl 2')\n",
    "if outer_range>3:\n",
    "    f_ax3.plot(np.arange(1*fs)/fs, pitch_dict[3])\n",
    "    f_ax3.set_title('Pitch Shift lvl 3')\n",
    "if outer_range>4:\n",
    "    f_ax4.plot(np.arange(1*fs)/fs, pitch_dict[4])\n",
    "    f_ax4.set_title('Pitch Shift lvl 4')\n",
    "if outer_range>5:\n",
    "    f_ax5.plot(np.arange(1*fs)/fs, pitch_dict[5])\n",
    "    f_ax5.set_title('Pitch Shift lvl 5')\n",
    "if outer_range>6:\n",
    "    f_ax6.plot(np.arange(1*fs)/fs, pitch_dict[6])\n",
    "    f_ax6.set_title('Pitch Shift lvl 6')\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23c715",
   "metadata": {},
   "source": [
    "#### Listen to Pitch Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb33348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Original:\")\n",
    "display(Audio(pitch_dict[0], rate=fs))\n",
    "\n",
    "if outer_range>1:\n",
    "    print(\"Pitch Shift lvl 1\")\n",
    "    display(Audio(pitch_dict[1], rate=fs))\n",
    "if outer_range>2:\n",
    "    print(\"Pitch Shift lvl 2\")\n",
    "    display(Audio(pitch_dict[2], rate=fs))\n",
    "if outer_range>3:\n",
    "    print(\"Pitch Shift lvl 3\")\n",
    "    display(Audio(pitch_dict[3], rate=fs))\n",
    "if outer_range>4:\n",
    "    print(\"Pitch Shift lvl 4\")\n",
    "    display(Audio(pitch_dict[3], rate=fs))\n",
    "if outer_range>5:\n",
    "    print(\"Pitch Shift lvl 5\")\n",
    "    display(Audio(pitch_dict[4], rate=fs))\n",
    "if outer_range>6:\n",
    "    print(\"Pitch Shift lvl 6\")\n",
    "    display(Audio(pitch_dict[5], rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a3559",
   "metadata": {},
   "source": [
    "# Additional Augmentations\n",
    "    *These change volume\n",
    "    *Still needs work, suggest staying with previous augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Testing if audio data imported correctly\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ef568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Sample count:\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163aaad",
   "metadata": {},
   "source": [
    "#### Icrease audio sample amplitude by multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increases existing audios volume/amplitue \n",
    "multiplier=3\n",
    "for i in range(1,multiplier):\n",
    "    for index in range(len(filenames)):\n",
    "            test_wav=filenames[index]\n",
    "            fs, test_wav = wavfile.read(test_wav)\n",
    "            sound=test_wav*(i)\n",
    "            sound_normalized=sound.astype(np.int16)\n",
    "            current_name = str(keyword_directory) + str(keyword)+f\"noiseLVL_{i}_{index}.wav\" \n",
    "            write(current_name, fsamp, sound_normalized)\n",
    "\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "print(\"Multiplier complete\")\n",
    "print(\"Sample count:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ba5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav=filenames[250]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f9062",
   "metadata": {},
   "source": [
    "#### Normalize to specific amplitude level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e682e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=12000\n",
    "for index in range(len(filenames)):\n",
    "        test_wav=filenames[index]\n",
    "        fs, test_wav = wavfile.read(test_wav)\n",
    "        sound = test_wav*(noise_level/max(test_wav))\n",
    "        sound_normalized=sound.astype(np.int16)\n",
    "        current_name = str(keyword_directory) + str(keyword)+f\"_{index}.wav\" \n",
    "        #current_name = filenames[index]\n",
    "        write(current_name, fsamp, sound_normalized)\n",
    "        if ((index%10)==0):\n",
    "            print(f\"{index}/{len(filenames)} complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav=filenames[250]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c668b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f3a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
