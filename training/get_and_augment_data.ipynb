{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f98bbad",
   "metadata": {},
   "source": [
    "# Audio Capture & Augmentation\n",
    "#### Author: Jeromey Schwartz\n",
    "#### *Audio capture code (indicated with *) supplied by Dr. Jeremy Holleman UNC-Charlotte "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e85322b",
   "metadata": {},
   "source": [
    "### Purpose:\n",
    "This will record an audio sample 1 second long at a sampling rate of 16kHz, the samples can then be augmented by adding noise, pitch shifting, or time shifting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0398a4",
   "metadata": {},
   "source": [
    "### Program Flow:\n",
    "1. Load libraries/setup code \n",
    "2. Save a number of audio samples \n",
    "3. Save ambient noise samples \n",
    "4. Noise shift \n",
    "5. Time shift \n",
    "6. Pitch shift \n",
    "7. Save samples names in validation document "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd7b44af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4914f189",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a0c1da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 20:28:05.013478: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-04 20:28:05.042624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 20:28:05.497645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PY_SSIZE_T_CLEAN'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "from datetime import datetime as dt\n",
    "from numpy import log as ln\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import pyaudio\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import math\n",
    "import time\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93e449",
   "metadata": {},
   "source": [
    "#### Set Parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e632d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i16min            = -32768\n",
    "i16max            = 32767\n",
    "fsamp             = 16000\n",
    "wave_length_ms    = 1000\n",
    "wave_length_samps = 16000\n",
    "window_size_ms    = 60\n",
    "window_step_ms    = 40\n",
    "num_filters       = 32\n",
    "use_microfrontend = True\n",
    "keyword        = 'computer'#####Insert your keyword\n",
    "spectrogram_shape = (64, 24, 32, 1)\n",
    "\n",
    "chunk_duration = 0.25 # Each read length in seconds from mic.\n",
    "fs = 16000 # sampling rate for mic\n",
    "sample_rate = 16000 # sampling rate for mic\n",
    "chunk_samples = int(fs * chunk_duration) # Each read length in number of samples.\n",
    "\n",
    "# Each model input data duration in seconds, need to be an integer numbers of chunk_duration\n",
    "feed_duration = 1.0\n",
    "feed_samples = int(fs * feed_duration)\n",
    "\n",
    "assert feed_duration/chunk_duration == int(feed_duration/chunk_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6456e",
   "metadata": {},
   "source": [
    "#### Create keyword & noise folders*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b7bdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/GitHub/project-2-team-1/training/custom-speech/computer/\n",
      "Directory 'computer' created\n",
      "Directory 'noise' created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the parent directory\n",
    "parent_dir = os.getcwd()\n",
    "parent_dir = os.path.join(parent_dir, \"custom-speech\")\n",
    "\n",
    "# Get the name of the current keyword\n",
    "keyword = \"computer\"\n",
    "\n",
    "# Create the folder name and path\n",
    "folder = keyword\n",
    "dir = os.path.join(parent_dir, folder)\n",
    "\n",
    "# Create the directories if they do not exist\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "folder = keyword\n",
    "dir = os.path.join(parent_dir, folder)\n",
    "noise_dir = os.path.join(parent_dir, \"noise\")\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "if not os.path.exists(noise_dir):\n",
    "    os.mkdir(noise_dir)\n",
    "\n",
    "keyword_directory = dir + '/'\n",
    "print(keyword_directory)\n",
    "\n",
    "# Check if the directories were created\n",
    "if os.path.exists(os.path.join(parent_dir, \"computer\")):\n",
    "    print(\"Directory 'computer' created\")\n",
    "if os.path.exists(os.path.join(parent_dir, \"noise\")):\n",
    "    print(\"Directory 'noise' created\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2691401",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d33f91",
   "metadata": {},
   "source": [
    "# Get Custom Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc895e",
   "metadata": {},
   "source": [
    "#### Run this code to get in an audio sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace0223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default input device:\n",
      "{'index': 0, 'structVersion': 2, 'name': 'HDA Intel PCH: ALC897 Analog (hw:0,0)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.005804988662131519, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': 0.034829931972789115, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n",
      "\n",
      "Default output device:\n",
      "{'index': 0, 'structVersion': 2, 'name': 'HDA Intel PCH: ALC897 Analog (hw:0,0)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.005804988662131519, 'defaultLowOutputLatency': 0.005804988662131519, 'defaultHighInputLatency': 0.034829931972789115, 'defaultHighOutputLatency': 0.034829931972789115, 'defaultSampleRate': 44100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_rate_samplerate.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_rate_samplerate.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib pcm_rate.c:1582:(snd_pcm_rate_open) Cannot find rate converter\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_rate_samplerate.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_rate_samplerate.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib pcm_rate.c:1582:(snd_pcm_rate_open) Cannot find rate converter\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_rate_speexrate.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_rate_speexrate.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib pcm_rate.c:1582:(snd_pcm_rate_open) Cannot find rate converter\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_rate_speexrate.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_rate_speexrate.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib pcm_rate.c:1582:(snd_pcm_rate_open) Cannot find rate converter\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_jack.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_jack.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_jack.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_jack.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_oss.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_oss.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_oss.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_oss.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_pipewire.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_pipewire.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_pipewire.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_pipewire.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_pulse.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_pulse.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_pulse.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_pulse.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_upmix.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_upmix.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_upmix.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_upmix.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_vdownmix.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_vdownmix.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_vdownmix.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_vdownmix.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_usb_stream.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_usb_stream.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_usb_stream.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_usb_stream.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_pulse.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_pulse.so: cannot open shared object file: No such file or directory)\n",
      "ALSA lib dlmisc.c:337:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_pulse.so (/home/david/anaconda3/lib/alsa-lib/libasound_module_pcm_pulse.so: cannot open shared object file: No such file or directory)\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "# Create a PyAudio object\n",
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "# Get the default input and output devices\n",
    "default_input_device = pa.get_default_input_device_info()\n",
    "default_output_device = pa.get_default_output_device_info()\n",
    "\n",
    "# Print information about the default devices\n",
    "print(\"Default input device:\")\n",
    "print(default_input_device)\n",
    "\n",
    "print(\"\\nDefault output device:\")\n",
    "print(default_output_device)\n",
    "\n",
    "# # Print information about all available devices\n",
    "# print(\"\\nAvailable devices:\")\n",
    "# for i in range(pa.get_device_count()):\n",
    "#     device_info = pa.get_device_info_by_index(i)\n",
    "#     print(device_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00064e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=10, micro=10, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info.\")\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288e6ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Queue to communiate between the audio callback and main thread\n",
    "q = Queue()\n",
    "run = True\n",
    "silence_threshold = 100\n",
    "# Run the demo for a timeout seconds\n",
    "timeout = time.time() + 1 \n",
    "# Data buffer for the input wavform\n",
    "data = np.zeros(feed_samples, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > feed_samples:\n",
    "        data = data[-feed_samples:]\n",
    "        # Process data async by sending a queue.\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = pyaudio.PyAudio().open(\n",
    "    format=pyaudio.paInt16,\n",
    "    channels=1,\n",
    "    rate=fs,\n",
    "    input=True,\n",
    "    frames_per_buffer=chunk_samples,\n",
    "    input_device_index=23,\n",
    "    stream_callback=callback)\n",
    "stream.start_stream()\n",
    "try:\n",
    "    while run:        \n",
    "        data = q.get()\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False      \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "sample_rate = fs\n",
    "\n",
    "\n",
    "#Displaying wave file data\n",
    "plt.plot(np.arange(1*fs)/fs, data)\n",
    "plt.show()\n",
    "ipd.Audio(data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ac719",
   "metadata": {},
   "source": [
    "#### If the Sample looks good run cell below to save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802139e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #saving the wave file to training_data\n",
    "# date_str = dt.now().strftime(\"%H%M%S\").lower()\n",
    "# current_name = f\"{keyword_directory}{keyword}_{date_str}.wav\".replace(\"\\\\\", \"/\")\n",
    "# write(current_name, sample_rate, data)\n",
    "# print(\"Audio sample saved\")\n",
    "# print(current_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32de0a5",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "* To get noise data run \"get data\" loop again to get ambient room\n",
    "* Save here\n",
    "* Get ~3 samples total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the wave file to training_data\n",
    "date_str = dt.now().strftime(\"%H%M%S\").lower()\n",
    "current_name = f\"{parent_dir}/noise/noise_{date_str}.wav\"\n",
    "write(current_name, sample_rate, data)\n",
    "print(\"Audio sample saved as noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c59cc",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Noise\n",
    "    * This will create copies of sample audio and add pre-recorded noise. \n",
    "    * The amplitude of the noise depends on *noise_count*\n",
    "    * Audio samples and visualizations are created to show noise augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7813e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting augmentation folder & files\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "\n",
    "#Testing if audio data imported correctly\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading noise samples\n",
    "noise_dir = parent_dir+'/noise'\n",
    "noise_samples = tf.io.gfile.glob(str(noise_dir) + '/*.wav')\n",
    "print(\"Noise Samples:\", len(noise_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca02bd",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b00e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise_count will deteremine how many augmentations will be created\n",
    "    #noise_count=1 will be a copy with noise augmentation * 0\n",
    "    #noise_count=2 will be noise_count=1 plus a copy with noise augmentation * 1\n",
    "    #noise_count=2 will be noise_count=2 plus a copy with noise augmentation * 2  \n",
    "    #and so on \n",
    "\n",
    "noise_count=4\n",
    "print(\"This will expand the current\", len(filenames), \"files by creating an addtional\",len(filenames)*len(noise_samples)*noise_count, \"noise augmented files, to give a total of\",len(filenames)*len(noise_samples)*(noise_count)+len(filenames),\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a67c2c",
   "metadata": {},
   "source": [
    "#### Creating Noise Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict holds samples for plotting\n",
    "noise_dict={}\n",
    "for index in range(len(filenames)):\n",
    "    test_wav=filenames[index]\n",
    "    fs, test_wav = wavfile.read(test_wav)\n",
    "    if (len(test_wav) < fs):\n",
    "        padding=fs-len(test_wav)\n",
    "        extra_padding=np.zeros(padding).astype(np.int16) #array of empty audio to pad with\n",
    "        test_wav=np.concatenate((test_wav,extra_padding),axis=0).astype(np.int16)\n",
    "    noise_dict[0]=test_wav.astype(np.int16)\n",
    "    for i in range(len(noise_samples)):\n",
    "        noise=noise_samples[i]\n",
    "        fs, noise = wavfile.read(noise)\n",
    "        for j in range(noise_count):\n",
    "            noise_multiplier=round(max(test_wav)*(j/2000))\n",
    "            noise_lvl=noise*noise_multiplier\n",
    "            test_wave_with_noise=np.add(test_wav,noise_lvl)\n",
    "            current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_Noise{i}_Multiplier{j}.wav\"\n",
    "            write(current_name, fs, test_wave_with_noise)\n",
    "            noise_dict[j+1]=test_wave_with_noise.astype(np.int16)\n",
    "            noise_dict[j+5]=noise_lvl.astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b9b33",
   "metadata": {},
   "source": [
    "#### Plotting noise augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only plots up to noise lvl 3\n",
    "fig, axs = plt.subplots(4, 4,figsize=(20,10), sharex=True,sharey=True)\n",
    "axs[0,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[0,1].plot(np.arange(1*fs)/fs, noise_dict[5], 'tab:orange')\n",
    "axs[0,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[0,2].plot(np.arange(1*fs)/fs, noise_dict[5])\n",
    "axs[0,3].plot(np.arange(1*fs)/fs, noise_dict[1])\n",
    "\n",
    "axs[0, 0].set_title(\"Original\")\n",
    "axs[0, 1].set_title(\"Noise\")\n",
    "axs[0, 2].set_title(\"Original + Noise\")\n",
    "axs[0, 3].set_title(\"Augmented Audio\")\n",
    "\n",
    "axs[0, 0].set(xlabel='Time (s)', ylabel='Noise lvl 0')\n",
    "axs[1, 0].set(xlabel='Time (s)', ylabel='Noise lvl 1')\n",
    "axs[2, 0].set(xlabel='Time (s)', ylabel='Noise lvl 2')\n",
    "axs[3, 0].set(xlabel='Time (s)', ylabel='Noise lvl 3')\n",
    "\n",
    "axs[1,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[1,1].plot(np.arange(1*fs)/fs, noise_dict[6], 'tab:orange')\n",
    "axs[1,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[1,2].plot(np.arange(1*fs)/fs, noise_dict[6])\n",
    "axs[1,3].plot(np.arange(1*fs)/fs, noise_dict[2])\n",
    "\n",
    "axs[2,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[2,1].plot(np.arange(1*fs)/fs, noise_dict[7], 'tab:orange')\n",
    "axs[2,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[2,2].plot(np.arange(1*fs)/fs, noise_dict[7])\n",
    "axs[2,3].plot(np.arange(1*fs)/fs, noise_dict[3])\n",
    "\n",
    "axs[3,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[3,1].plot(np.arange(1*fs)/fs, noise_dict[8], 'tab:orange')\n",
    "axs[3,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[3,2].plot(np.arange(1*fs)/fs, noise_dict[8])\n",
    "axs[3,3].plot(np.arange(1*fs)/fs, noise_dict[4])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Time (s)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f4855",
   "metadata": {},
   "source": [
    "#### Listen to noise augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c692f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only samples up to noise lvl 3\n",
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Noise lvl 0:\")\n",
    "display(Audio(noise_dict[0], rate=fs))\n",
    "print(\"Noise lvl 1:\")\n",
    "display(Audio(noise_dict[2], rate=fs))\n",
    "print(\"Noise lvl 2:\")\n",
    "display(Audio(noise_dict[3], rate=fs))\n",
    "print(\"Noise lvl 3:\")\n",
    "display(Audio(noise_dict[4], rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f40a1",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Pitch Shift\n",
    "    * This will create copies of sample audio and pitch shift them\n",
    "    * The variable *pitch_shift* allows control over pitch\n",
    "    * The variable *desired_number_of_files* allows control of exactly how many samples to create\n",
    "    * The loop will continue creating copies until desired count is reached, including pitch shifting already pitch shifted copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Testing if audio data imported correctly\n",
    "filenames[0]\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The current number of files in directory is\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee19898",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample count:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Verifying opens files correctly\n",
    "print(filenames[0])\n",
    "\n",
    "num_files=len(filenames)\n",
    "num_files\n",
    "print(\"Total files:\", num_files)\n",
    "\n",
    "#randomizes order of samples for validation list\n",
    "random_list = list(range(0, num_files)) #create array [1,2,3...]\n",
    "random.shuffle(random_list) #randomize the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59406c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many of the files do you want to have total?\n",
    "desired_number_of_files=4000\n",
    "\n",
    "#How do you want to pitch shift\n",
    "    #positive=high pitch, negative = low pitch\n",
    "    #0.25 is a good value\n",
    "pitch_shift=0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa7c992",
   "metadata": {},
   "source": [
    "### Doubling Equation:   \n",
    "> $output=input * 2^{x}$\n",
    "\n",
    "*Here $x$ is the number of times input is doubled\n",
    "\n",
    "#### To get desired number of output files from input when loop doubles input every iteration of the for loop we solve for $x$:\n",
    "   \n",
    "> $x=\\log _{2}(\\frac{out}{in})$\\\n",
    "  $x=\\frac{\\ln (\\frac{out}{in})} {\\ln (2)}$\n",
    "                 \n",
    "#### Next $math.ceil()$ is used to round up to integer for loop iteration\n",
    "\n",
    "> $x=$ math.ceil$(\\frac{\\ln (out)}{\\ln (in)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doubling formula used to find range for outer for loop indexing with \"i\"\n",
    "outer_range= math.ceil((np.log(desired_number_of_files / len(filenames)) / np.log(2) ))\n",
    "outer_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d116a7",
   "metadata": {},
   "source": [
    "#### Pitch Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909afc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace line 11 with comment below if you want to create a custom # < len(filenames)...\n",
    "#                                                    ...comment out if statements and speed will improve significantly\n",
    "#for index in range(40000): \n",
    "\n",
    "pitch_dict={}\n",
    "for i in range(outer_range):\n",
    "    for index in range(len(filenames)):\n",
    "        test_wav=filenames[index]\n",
    "        fs, test_wav = wavfile.read(test_wav)\n",
    "        if i==0:\n",
    "            pitch_dict[i]=test_wav\n",
    "        test_wav_float=test_wav.astype(float)\n",
    "        test_wav_pitch_shifted = librosa.effects.pitch_shift(test_wav_float, sr=sample_rate, n_steps=pitch_shift*(i+1))\n",
    "        test_wav_pitch_shifted_int=test_wav_pitch_shifted.astype(np.int16)\n",
    "        current_name = str(keyword_directory)+str(keyword) +f\"_Pitch_Shift_{i}_{index}.wav\"    \n",
    "        write(current_name, fsamp, test_wav_pitch_shifted_int)\n",
    "\n",
    "        files_in_folder=len(tf.io.gfile.glob(str(data_dir) + '/*.wav'))\n",
    "        pitch_dict[i+1]=test_wav_pitch_shifted_int\n",
    "        if (files_in_folder >= desired_number_of_files):\n",
    "            break \n",
    "    filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "    #update filenames with newly created files    \n",
    "    if (files_in_folder >= desired_number_of_files):\n",
    "        break \n",
    "print(\"Congratulations, the current number of files in directory is\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4aea1e",
   "metadata": {},
   "source": [
    "#### Plot Pitch Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True)\n",
    "axs = fig.add_gridspec(3, 3)\n",
    "\n",
    "f_ax0 = fig.add_subplot(axs[0, 1])\n",
    "f_ax1 = fig.add_subplot(axs[1, 0])\n",
    "f_ax2 = fig.add_subplot(axs[1, 1])\n",
    "f_ax3 = fig.add_subplot(axs[1, 2])\n",
    "f_ax4 = fig.add_subplot(axs[2, 0])\n",
    "f_ax5 = fig.add_subplot(axs[2, 1])\n",
    "f_ax6 = fig.add_subplot(axs[2, 2])\n",
    "\n",
    "f_ax0.plot(np.arange(1*fs)/fs, pitch_dict[0])\n",
    "f_ax0.set_title('Original')\n",
    "\n",
    "if outer_range>1:\n",
    "    f_ax1.plot(np.arange(1*fs)/fs, pitch_dict[1])\n",
    "    f_ax1.set_title('Pitch Shift lvl 1')\n",
    "if outer_range>2:\n",
    "    f_ax2.plot(np.arange(1*fs)/fs, pitch_dict[2])\n",
    "    f_ax2.set_title('Pitch Shift lvl 2')\n",
    "if outer_range>3:\n",
    "    f_ax3.plot(np.arange(1*fs)/fs, pitch_dict[3])\n",
    "    f_ax3.set_title('Pitch Shift lvl 3')\n",
    "if outer_range>4:\n",
    "    f_ax4.plot(np.arange(1*fs)/fs, pitch_dict[4])\n",
    "    f_ax4.set_title('Pitch Shift lvl 4')\n",
    "if outer_range>5:\n",
    "    f_ax5.plot(np.arange(1*fs)/fs, pitch_dict[5])\n",
    "    f_ax5.set_title('Pitch Shift lvl 5')\n",
    "if outer_range>6:\n",
    "    f_ax6.plot(np.arange(1*fs)/fs, pitch_dict[6])\n",
    "    f_ax6.set_title('Pitch Shift lvl 6')\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23c715",
   "metadata": {},
   "source": [
    "#### Listen to Pitch Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb33348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Original:\")\n",
    "display(Audio(pitch_dict[0], rate=fs))\n",
    "\n",
    "if outer_range>1:\n",
    "    print(\"Pitch Shift lvl 1\")\n",
    "    display(Audio(pitch_dict[1], rate=fs))\n",
    "if outer_range>2:\n",
    "    print(\"Pitch Shift lvl 2\")\n",
    "    display(Audio(pitch_dict[2], rate=fs))\n",
    "if outer_range>3:\n",
    "    print(\"Pitch Shift lvl 3\")\n",
    "    display(Audio(pitch_dict[3], rate=fs))\n",
    "if outer_range>4:\n",
    "    print(\"Pitch Shift lvl 4\")\n",
    "    display(Audio(pitch_dict[3], rate=fs))\n",
    "if outer_range>5:\n",
    "    print(\"Pitch Shift lvl 5\")\n",
    "    display(Audio(pitch_dict[4], rate=fs))\n",
    "if outer_range>6:\n",
    "    print(\"Pitch Shift lvl 6\")\n",
    "    display(Audio(pitch_dict[5], rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f3a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d490e2a9",
   "metadata": {},
   "source": [
    "# Write augmented data files to testing and validation .txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888feccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Set the paths and file names for the train, test, and validation files\n",
    "train_file_name = './custom-speech/training_list.txt'\n",
    "test_file_name = './custom-speech/testing_list.txt'\n",
    "val_file_name = './custom-speech/validation_list.txt'\n",
    "\n",
    "# Set the split percentages\n",
    "train_pct = 0.7\n",
    "test_pct = 0.2\n",
    "val_pct = 0.1\n",
    "\n",
    "# Set the directory path containing the WAV files\n",
    "data_dir = './custom-speech'\n",
    "\n",
    "# Create a list of keywords (folder names)\n",
    "keywords = ['yes','right','left','computer']\n",
    "\n",
    "# Create an empty list to store all the WAV files\n",
    "wav_files = []\n",
    "\n",
    "# Iterate over all the keywords and add their respective WAV files to the list\n",
    "for keyword in keywords:\n",
    "    # Get a list of all WAV files in the keyword directory\n",
    "    keyword_files = tf.io.gfile.glob(str(os.path.join(data_dir, keyword)) + '/*.wav')\n",
    "    # Add the keyword files to the list of all WAV files\n",
    "    wav_files += keyword_files\n",
    "\n",
    "# Shuffle the files randomly\n",
    "random.shuffle(wav_files)\n",
    "\n",
    "# Calculate the number of files for each split\n",
    "num_files = len(wav_files)\n",
    "num_train = int(train_pct*num_files)\n",
    "num_test = int(test_pct*num_files)\n",
    "num_val = num_files - num_train - num_test\n",
    "\n",
    "# Append the train list file\n",
    "with open(train_file_name, 'a') as f:\n",
    "    for file in wav_files[:num_train]:\n",
    "        f.write(os.path.join(os.path.basename(os.path.dirname(file)), os.path.basename(file)) + '\\n')\n",
    "print(num_train, \"samples added to\", train_file_name)\n",
    "\n",
    "# Append the test list file\n",
    "with open(test_file_name, 'a') as f:\n",
    "    for file in wav_files[num_train:num_train+num_test]:\n",
    "        f.write(os.path.join(os.path.basename(os.path.dirname(file)), os.path.basename(file)) + '\\n')\n",
    "print(num_test, \"samples added to\", test_file_name)\n",
    "\n",
    "# Append the validation list file\n",
    "with open(val_file_name, 'a') as f:\n",
    "    for file in wav_files[num_train+num_test:]:\n",
    "        f.write(os.path.join(os.path.basename(os.path.dirname(file)), os.path.basename(file)) + '\\n')\n",
    "print(num_val, \"samples added to\", val_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = './custom-speech/'\n",
    "\n",
    "folder_counts = {}\n",
    "for subdir in os.listdir(data_dir):\n",
    "    subdir_path = os.path.join(data_dir, subdir)\n",
    "    if os.path.isdir(subdir_path) and subdir != 'speech_commands_v0.02':\n",
    "        folder_counts[subdir] = len([f for f in os.listdir(subdir_path) if f.endswith('.wav')])\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "sorted_keys = sorted(folder_counts.keys())\n",
    "plt.bar(range(len(folder_counts)), [folder_counts[key] for key in sorted_keys], align='center')\n",
    "plt.xticks(range(len(folder_counts)), sorted_keys, rotation=90)\n",
    "plt.ylabel('Number of WAV Files')\n",
    "plt.title('WAV Files by Folder')\n",
    "plt.savefig('/home/david/Documents/GitHub/project-2-team-1/training/figs/all wav files')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
